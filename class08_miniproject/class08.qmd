---
title: "Class 8: Breast Cancer Mini Project"
author: "Barry (PID 911)"
format: html
---

## Outline
Today we will apply the machine learning methods we introduced in the last class on breast cancer biopsy data from fine needle aspiration (FNA).

## Data input
The data is supplied on CSV format:

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
head(wisc.df)
```

Now I will store the diagnosis column for later and exclude it from the data set I will actually do things with that I will call `wisc.data`

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
wisc.data <- wisc.df[,-1]
```

> Q1 How many people are in this data set?

```{r}
nrow(wisc.df)
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
table( wisc.df$diagnosis )
```
```{r}
sum(wisc.df$diagnosis == "M")
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
x <- colnames(wisc.df)
length( grep("_mean", x) )
```

```{r}
x
```

# Principal Component Analysis

We need to scale our input data before PCA as some of the columns are measured in terms of very different units with different means and different variances. The upshot here is we set `scale=TRUE` argument to `prcomp()`.

```{r}
wisc.pr <- prcomp( wisc.data, scale=TRUE )
summary(wisc.pr)
```

Generate one of our main result figures - the PC plot (a.k.a. "score plot", "orientation plot", "PC1 vs PC2 plot", "PC plot", "projection plot", etc.) It is known by different names in different fields.

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```
And a ggplot version

```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Load the ggplot2 package
library(ggplot2)

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

# Hierarchical clustering

Can we just use clustering on the original data and get some insight into M vs B?

It is rather difficult, this "tree" looks like a hot mess...

```{r}
# distance matrix needed for hclust
data.dist <- dist( scale(wisc.data) )

wisc.hclust <- hclust(data.dist)
plot(wisc.hclust)
```

## 5. Combining methods

This approach will take not original data but our PCA results and work with them.

```{r}
d <- dist( wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(d, method="ward.D2")
plot(wisc.pr.hclust)
```

Generate 2 cluster groups from this hclust object.

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
grps
```

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps)
```

```{r}
table(grps)
```

```{r}
table(diagnosis)
```
```{r}
table(diagnosis, grps)
```

